# -*- coding: utf-8 -*-
"""solubility.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14azuEYS8CUwvu2Ex4y8usB7n2m7zlKbE
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Dichloromethane solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('dichloromethane', na=False)]

if not solv_matches.empty:
    dichloromethane_id = solv_matches['solvent'].values[0]
    print("Matched Dichloromethane solvent ID:", dichloromethane_id)
else:
    print("Dichloromethane not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Dichloromethane not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Dichloromethane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == dichloromethane_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Dichloromethane)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Dichloromethane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PI polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.fullmatch('pi', na=False)]

if not poly_matches.empty:
    poly_id = poly_matches['polymer'].values[0]
    print("Matched PI polymer ID:", poly_id)
else:
    print("PI not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PI not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Benzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('benzene', na=False)]

if not solv_matches.empty:
    solv_id = solv_matches['solvent'].values[0]
    print("Matched Benzene solvent ID:", solv_id)
else:
    print("Benzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Benzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PI–Benzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == poly_id) & (df_n["solvent"] == solv_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PI - Benzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PI - Benzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get Matrimid polymer ID and Carbon Dioxide solvent ID
matrimid_id = df_pinfo[df_pinfo['abr'].str.lower() == 'matrimid']['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for Matrimid–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)  # Swap polymer and solvent
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()  # Keep sol-pol in the dataset
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1  # suppress LightGBM warnings
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],  # Retrieve the sol-pol value for the output
    'RMSE': [rmse],
    'R² Score': [r2]
})

# Display the output
print(output)

# Step 9: Visualizations
# 1. Solubility vs Temperature
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='temperature', y='wa')
plt.title('Solubility vs Temperature (Matrimid - CO2)')
plt.show()

# 2. Solubility vs Pressure
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='pressure', y='wa')
plt.title('Solubility vs Pressure (Matrimid - CO2)')
plt.show()

# 3. Solubility vs Polymer Density
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='dens', y='wa')
plt.title('Solubility vs Polymer Density (Matrimid - CO2)')
plt.show()

# 4. Solubility vs Glass Transition Temperature (Tg)
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='tg', y='wa')
plt.title('Solubility vs Tg (Matrimid - CO2)')
plt.show()

# 5. Solubility vs Molecular Weight (Mw)
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='mw', y='wa')
plt.title('Solubility vs Mw (Matrimid - CO2)')
plt.show()

# 6. Solubility vs Number Average Molecular Weight (Mn)
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='mn', y='wa')
plt.title('Solubility vs Mn (Matrimid - CO2)')
plt.show()

# 7. Solubility vs Crystalline Fraction
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='cryst', y='wa')
plt.title('Solubility vs Crystalline Fraction (Matrimid - CO2)')
plt.show()

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - CO2)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PIB polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.fullmatch('pib', na=False)]

if not poly_matches.empty:
    poly_id = poly_matches['polymer'].values[0]
    print("Matched PIB polymer ID:", poly_id)
else:
    print("PIB not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PIB not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Benzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('benzene', na=False)]

if not solv_matches.empty:
    solv_id = solv_matches['solvent'].values[0]
    print("Matched Benzene solvent ID:", solv_id)
else:
    print("Benzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Benzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PIB–Benzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == poly_id) & (df_n["solvent"] == solv_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PIB - Benzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PIB - Benzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Methane solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('methane', na=False)]

if not solv_matches.empty:
    methane_id = solv_matches['solvent'].values[0]
    print("Matched Methane solvent ID:", methane_id)
else:
    print("Methane not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Methane not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Methane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == methane_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Methane)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Methane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PBMA polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.fullmatch('pbma', na=False)]

if not poly_matches.empty:
    poly_id = poly_matches['polymer'].values[0]
    print("Matched PBMA polymer ID:", poly_id)
else:
    print("PBMA not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PBMA not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Benzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('benzene', na=False)]

if not solv_matches.empty:
    solv_id = solv_matches['solvent'].values[0]
    print("Matched Benzene solvent ID:", solv_id)
else:
    print("Benzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Benzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PBMA–Benzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == poly_id) & (df_n["solvent"] == solv_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PBMA - Benzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PBMA - Benzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Water solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('water', na=False)]

if not solv_matches.empty:
    water_id = solv_matches['solvent'].values[0]
    print("Matched Water solvent ID:", water_id)
else:
    print("Water not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Water not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Water data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == water_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Water)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Water)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PVAc polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.fullmatch('pvac', na=False)]

if not poly_matches.empty:
    poly_id = poly_matches['polymer'].values[0]
    print("Matched PVAc polymer ID:", poly_id)
else:
    print("PVAc not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PVAc not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Benzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('benzene', na=False)]

if not solv_matches.empty:
    solv_id = solv_matches['solvent'].values[0]
    print("Matched Benzene solvent ID:", solv_id)
else:
    print("Benzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Benzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PVAc–Benzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == poly_id) & (df_n["solvent"] == solv_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PVAc - Benzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PVAc - Benzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Water solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('water', na=False)]

if not solv_matches.empty:
    water_id = solv_matches['solvent'].values[0]
    print("Matched Water solvent ID:", water_id)
else:
    print("Water not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Water not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Water data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == water_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Water)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Water)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PI polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pi', na=False)]

if not poly_matches.empty:
    pi_id = poly_matches['polymer'].values[0]
    print("Matched PI polymer ID:", pi_id)
else:
    print("PI not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PI not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Benzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('benzene', na=False)]

if not solv_matches.empty:
    benzene_id = solv_matches['solvent'].values[0]
    print("Matched Benzene solvent ID:", benzene_id)
else:
    print("Benzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Benzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PI–Benzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pi_id) & (df_n["solvent"] == benzene_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PI - Benzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PI - Benzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Methylacetate solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('methylacetate', na=False)]

if not solv_matches.empty:
    methylacetate_id = solv_matches['solvent'].values[0]
    print("Matched Methylacetate solvent ID:", methylacetate_id)
else:
    print("Methylacetate not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Methylacetate not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Methylacetate data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == methylacetate_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Methylacetate)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Methylacetate)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PIB polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pib', na=False)]

if not poly_matches.empty:
    pib_id = poly_matches['polymer'].values[0]
    print("Matched PIB polymer ID:", pib_id)
else:
    print("PIB not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PIB not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Benzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('benzene', na=False)]

if not solv_matches.empty:
    benzene_id = solv_matches['solvent'].values[0]
    print("Matched Benzene solvent ID:", benzene_id)
else:
    print("Benzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Benzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PIB–Benzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pib_id) & (df_n["solvent"] == benzene_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PIB - Benzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PIB - Benzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Acetone solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('acetone', na=False)]

if not solv_matches.empty:
    acetone_id = solv_matches['solvent'].values[0]
    print("Matched Acetone solvent ID:", acetone_id)
else:
    print("Acetone not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Acetone not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Acetone data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == acetone_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Acetone)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Acetone)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PBMA polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pbma', na=False)]

if not poly_matches.empty:
    pbma_id = poly_matches['polymer'].values[0]
    print("Matched PBMA polymer ID:", pbma_id)
else:
    print("PBMA not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PBMA not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Benzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('benzene', na=False)]

if not solv_matches.empty:
    benzene_id = solv_matches['solvent'].values[0]
    print("Matched Benzene solvent ID:", benzene_id)
else:
    print("Benzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Benzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PBMA–Benzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pbma_id) & (df_n["solvent"] == benzene_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PBMA - Benzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PBMA - Benzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get Matrimid polymer ID and Methanol solvent ID
matrimid_id = df_pinfo[df_pinfo['abr'].str.lower() == 'matrimid']['polymer'].values[0]
methanol_id = df_sinfo[df_sinfo['name'].str.lower() == 'methanol']['solvent'].values[0]

# Step 3: Filter for Matrimid–Methanol data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)  # Swap polymer and solvent
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == methanol_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()  # Keep sol-pol in the dataset
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1  # suppress LightGBM warnings
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],  # Retrieve the sol-pol value for the output
    'RMSE': [rmse],
    'R² Score': [r2]
})

# Display the output
print(output)

# Step 9: Feature Importance (optional)
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Methanol)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PVAc polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pvac', na=False)]

if not poly_matches.empty:
    pvac_id = poly_matches['polymer'].values[0]
    print("Matched PVAc polymer ID:", pvac_id)
else:
    print("PVAc not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PVAc not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Benzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('benzene', na=False)]

if not solv_matches.empty:
    benzene_id = solv_matches['solvent'].values[0]
    print("Matched Benzene solvent ID:", benzene_id)
else:
    print("Benzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Benzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PVAc–Benzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pvac_id) & (df_n["solvent"] == benzene_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PVAc - Benzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PVAc - Benzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get Matrimid polymer ID and Carbon Dioxide solvent ID
matrimid_id = df_pinfo[df_pinfo['abr'].str.lower() == 'matrimid']['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for Matrimid–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)  # Swap polymer and solvent
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()  # Keep sol-pol in the dataset
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1  # suppress LightGBM warnings
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],  # Retrieve the sol-pol value for the output
    'RMSE': [rmse],
    'R² Score': [r2]
})

# Display the output
print(output)

# Step 9: Feature Importance (optional)
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - CO2)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PBMA polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pbma', na=False)]

if not poly_matches.empty:
    pbma_id = poly_matches['polymer'].values[0]
    print("Matched PBMA polymer ID:", pbma_id)
else:
    print("PBMA not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PBMA not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Dichloromethane solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('dichloromethane', na=False)]

if not solv_matches.empty:
    dichloromethane_id = solv_matches['solvent'].values[0]
    print("Matched Dichloromethane solvent ID:", dichloromethane_id)
else:
    print("Dichloromethane not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Dichloromethane not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PBMA–Dichloromethane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pbma_id) & (df_n["solvent"] == dichloromethane_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PBMA - Dichloromethane)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PBMA - Dichloromethane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Nitrogen solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('nitrogen', na=False)]

if not solv_matches.empty:
    nitrogen_id = solv_matches['solvent'].values[0]
    print("Matched Nitrogen solvent ID:", nitrogen_id)
else:
    print("Nitrogen not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Nitrogen not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Nitrogen data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == nitrogen_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Nitrogen)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PIB polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pib', na=False)]

if not poly_matches.empty:
    pib_id = poly_matches['polymer'].values[0]
    print("Matched PIB polymer ID:", pib_id)
else:
    print("PIB not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PIB not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Dichloromethane solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('dichloromethane', na=False)]

if not solv_matches.empty:
    dichloromethane_id = solv_matches['solvent'].values[0]
    print("Matched Dichloromethane solvent ID:", dichloromethane_id)
else:
    print("Dichloromethane not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Dichloromethane not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PIB–Dichloromethane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pib_id) & (df_n["solvent"] == dichloromethane_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PIB - Dichloromethane)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PIB - Dichloromethane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get Matrimid polymer ID and Acetone solvent ID
matrimid_id = df_pinfo[df_pinfo['abr'].str.lower() == 'matrimid']['polymer'].values[0]
acetone_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('acetone')]['solvent'].values[0]

# Step 3: Filter for Matrimid–Acetone data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)  # Swap polymer and solvent
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == acetone_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()  # Keep sol-pol in the dataset
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1  # suppress LightGBM warnings
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],  # Retrieve the sol-pol value for the output
    'RMSE': [rmse],
    'R² Score': [r2]
})

# Display the output
print(output)

# Step 9: Visualizations
# 1. Solubility vs Temperature
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='temperature', y='wa')
plt.title('Solubility vs Temperature (Matrimid - Acetone)')
plt.show()

# 2. Solubility vs Pressure
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='pressure', y='wa')
plt.title('Solubility vs Pressure (Matrimid - Acetone)')
plt.show()

# 3. Solubility vs Polymer Density
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='dens', y='wa')
plt.title('Solubility vs Polymer Density (Matrimid - Acetone)')
plt.show()

# 4. Solubility vs Glass Transition Temperature (Tg)
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='tg', y='wa')
plt.title('Solubility vs Tg (Matrimid - Acetone)')
plt.show()

# 5. Solubility vs Molecular Weight (Mw)
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='mw', y='wa')
plt.title('Solubility vs Mw (Matrimid - Acetone)')
plt.show()

# 6. Solubility vs Number Average Molecular Weight (Mn)
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='mn', y='wa')
plt.title('Solubility vs Mn (Matrimid - Acetone)')
plt.show()

# 7. Solubility vs Crystalline Fraction
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='cryst', y='wa')
plt.title('Solubility vs Crystalline Fraction (Matrimid - Acetone)')
plt.show()

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Acetone)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PVAc polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pvac', na=False)]

if not poly_matches.empty:
    pvac_id = poly_matches['polymer'].values[0]
    print("Matched PVAc polymer ID:", pvac_id)
else:
    print("PVAc not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PVAc not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Dichloromethane solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('dichloromethane', na=False)]

if not solv_matches.empty:
    dichloromethane_id = solv_matches['solvent'].values[0]
    print("Matched Dichloromethane solvent ID:", dichloromethane_id)
else:
    print("Dichloromethane not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Dichloromethane not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PVAc–Dichloromethane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pvac_id) & (df_n["solvent"] == dichloromethane_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PVAc - Dichloromethane)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PVAc - Dichloromethane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get Matrimid polymer ID and dichloromethane solvent ID
matrimid_id = df_pinfo[df_pinfo['abr'].str.lower() == 'matrimid']['polymer'].values[0]
dcm_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('dichloromethane')]['solvent'].values[0]

# Step 3: Filter for Matrimid–dichloromethane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == dcm_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='temperature', y='wa')
plt.title('Solubility vs Temperature (Matrimid - Dichloromethane)')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='pressure', y='wa')
plt.title('Solubility vs Pressure (Matrimid - Dichloromethane)')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='dens', y='wa')
plt.title('Solubility vs Polymer Density (Matrimid - Dichloromethane)')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='tg', y='wa')
plt.title('Solubility vs Tg (Matrimid - Dichloromethane)')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='mw', y='wa')
plt.title('Solubility vs Mw (Matrimid - Dichloromethane)')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='mn', y='wa')
plt.title('Solubility vs Mn (Matrimid - Dichloromethane)')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=filtered_df, x='cryst', y='wa')
plt.title('Solubility vs Crystalline Fraction (Matrimid - Dichloromethane)')
plt.show()

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Dichloromethane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PIB polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pib', na=False)]

if not poly_matches.empty:
    pib_id = poly_matches['polymer'].values[0]
    print("Matched PIB polymer ID:", pib_id)
else:
    print("PIB not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PIB not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Diethyl Ether solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('diethyl ether', na=False)]

if not solv_matches.empty:
    diethyl_ether_id = solv_matches['solvent'].values[0]
    print("Matched Diethyl Ether solvent ID:", diethyl_ether_id)
else:
    print("Diethyl Ether not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Diethyl Ether not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PIB–Diethyl Ether data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pib_id) & (df_n["solvent"] == diethyl_ether_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PIB - Diethyl Ether)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PIB - Diethyl Ether)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get Matrimid polymer ID and Methane solvent ID
matrimid_id = df_pinfo[df_pinfo['abr'].str.lower() == 'matrimid']['polymer'].values[0]
methane_id = df_sinfo[df_sinfo['name'].str.lower() == 'methane']['solvent'].values[0]

# Step 3: Filter for Matrimid–Methane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == methane_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
sol_pol_str = f"{df_sinfo[df_sinfo['solvent'] == methane_id]['name'].values[0]}-{df_pinfo[df_pinfo['polymer'] == matrimid_id]['abr'].values[0]}"
output = pd.DataFrame({
    'sol-pol': [sol_pol_str],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def boxplot_feature_vs_wa(feature, title_suffix):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=feature, y='wa')
    plt.title(f'Solubility vs {feature.capitalize()} ({sol_pol_str})')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

for feature in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    boxplot_feature_vs_wa(feature, sol_pol_str)

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {sol_pol_str})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PBMA polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pbma', na=False)]

if not poly_matches.empty:
    pbma_id = poly_matches['polymer'].values[0]
    print("Matched PBMA polymer ID:", pbma_id)
else:
    print("PBMA not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PBMA not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Diethyl Ether solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('diethyl ether', na=False)]

if not solv_matches.empty:
    diethyl_ether_id = solv_matches['solvent'].values[0]
    print("Matched Diethyl Ether solvent ID:", diethyl_ether_id)
else:
    print("Diethyl Ether not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Diethyl Ether not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PBMA–Diethyl Ether data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pbma_id) & (df_n["solvent"] == diethyl_ether_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PBMA - Diethyl Ether)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PBMA - Diethyl Ether)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Polyethylene polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('polyethylene|^pe$', na=False)]

if not poly_matches.empty:
    polyethylene_id = poly_matches['polymer'].values[0]
    print("Matched Polyethylene polymer ID:", polyethylene_id)
else:
    print("Polyethylene not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Polyethylene not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Nitrogen solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('nitrogen', na=False)]

if not solv_matches.empty:
    nitrogen_id = solv_matches['solvent'].values[0]
    print("Matched Nitrogen solvent ID:", nitrogen_id)
else:
    print("Nitrogen not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Nitrogen not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Polyethylene–Nitrogen data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == polyethylene_id) & (df_n["solvent"] == nitrogen_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyethylene - Nitrogen)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyethylene - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PVAc polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pvac', na=False)]

if not poly_matches.empty:
    pvac_id = poly_matches['polymer'].values[0]
    print("Matched PVAc polymer ID:", pvac_id)
else:
    print("PVAc not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PVAc not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Diethyl Ether solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('diethyl ether', na=False)]

if not solv_matches.empty:
    diethyl_ether_id = solv_matches['solvent'].values[0]
    print("Matched Diethyl Ether solvent ID:", diethyl_ether_id)
else:
    print("Diethyl Ether not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Diethyl Ether not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PVAc–Diethyl Ether data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pvac_id) & (df_n["solvent"] == diethyl_ether_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PVAc - Diethyl Ether)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PVAc - Diethyl Ether)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Polypropylene polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('polypropylene|^pp$', na=False)]

if not poly_matches.empty:
    polypropylene_id = poly_matches['polymer'].values[0]
    print("Matched Polypropylene polymer ID:", polypropylene_id)
else:
    print("Polypropylene not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Polypropylene not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Butane solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('butane', na=False)]

if not solv_matches.empty:
    butane_id = solv_matches['solvent'].values[0]
    print("Matched Butane solvent ID:", butane_id)
else:
    print("Butane not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Butane not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Polypropylene–Butane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == polypropylene_id) & (df_n["solvent"] == butane_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polypropylene - Butane)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polypropylene - Butane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PIB polymer ID (replace Matrimid with PIB)
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pib', na=False)]

if not poly_matches.empty:
    pib_id = poly_matches['polymer'].values[0]
    print("Matched PIB polymer ID:", pib_id)
else:
    print("PIB not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PIB not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Ethyl Acetate solvent ID (replace Methane with Ethyl Acetate)
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('ethyl acetate', na=False)]

if not solv_matches.empty:
    ethyl_acetate_id = solv_matches['solvent'].values[0]
    print("Matched Ethyl Acetate solvent ID:", ethyl_acetate_id)
else:
    print("Ethyl Acetate not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Ethyl Acetate not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PIB–Ethyl Acetate data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pib_id) & (df_n["solvent"] == ethyl_acetate_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PIB - Ethyl Acetate)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PIB - Ethyl Acetate)")
plt.tight_layout()
plt.show()

"""## **16**"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PBMA polymer ID (replace PIB with PBMA)
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pbma', na=False)]

if not poly_matches.empty:
    pbma_id = poly_matches['polymer'].values[0]
    print("Matched PBMA polymer ID:", pbma_id)
else:
    print("PBMA not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PBMA not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Ethyl Acetate solvent ID (unchanged)
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('ethyl acetate', na=False)]

if not solv_matches.empty:
    ethyl_acetate_id = solv_matches['solvent'].values[0]
    print("Matched Ethyl Acetate solvent ID:", ethyl_acetate_id)
else:
    print("Ethyl Acetate not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Ethyl Acetate not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PBMA–Ethyl Acetate data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pbma_id) & (df_n["solvent"] == ethyl_acetate_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PBMA - Ethyl Acetate)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PBMA - Ethyl Acetate)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get target polymer and Carbon Dioxide solvent ID
target_polymer_name = "polyether-imide poly(bisphenol-a-co-4- nitrophthalicanhydride-co-1,3-phenylenediamine)"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for polymer–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyether-imide - CO2)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyether-imide - CO2)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PVAc polymer ID (replace PIB with PVAc)
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pvac', na=False)]

if not poly_matches.empty:
    pvac_id = poly_matches['polymer'].values[0]
    print("Matched PVAc polymer ID:", pvac_id)
else:
    print("PVAc not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PVAc not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Ethyl Acetate solvent ID (unchanged)
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('ethyl acetate', na=False)]

if not solv_matches.empty:
    ethyl_acetate_id = solv_matches['solvent'].values[0]
    print("Matched Ethyl Acetate solvent ID:", ethyl_acetate_id)
else:
    print("Ethyl Acetate not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Ethyl Acetate not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PVAc–Ethyl Acetate data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pvac_id) & (df_n["solvent"] == ethyl_acetate_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PVAc - Ethyl Acetate)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PVAc - Ethyl Acetate)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find PVAc polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('pvac', na=False)]

if not poly_matches.empty:
    pvac_id = poly_matches['polymer'].values[0]
    print("Matched PVAc polymer ID:", pvac_id)
else:
    print("PVAc not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("PVAc not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Nitrobenzene solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('nitrobenzene', na=False)]

if not solv_matches.empty:
    nitrobenzene_id = solv_matches['solvent'].values[0]
    print("Matched Nitrobenzene solvent ID:", nitrobenzene_id)
else:
    print("Nitrobenzene not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Nitrobenzene not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for PVAc–Nitrobenzene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == pvac_id) & (df_n["solvent"] == nitrobenzene_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (PVAc - Nitrobenzene)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - PVAc - Nitrobenzene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get target polymer and Methane solvent ID
target_polymer_name = "polyether-imide poly(bisphenol-a-co-4- nitrophthalicanhydride-co-1,3-phenylenediamine)"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
methane_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('methane')]['solvent'].values[0]

# Step 3: Filter for polymer–Methane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == methane_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyether-imide - Methane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyether-imide - Methane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Methanol solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('methanol', na=False)]

if not solv_matches.empty:
    methanol_id = solv_matches['solvent'].values[0]
    print("Matched Methanol solvent ID:", methanol_id)
else:
    print("Methanol not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Methanol not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Methanol data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == methanol_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Methanol)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Methanol)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get target polymer and Nitrogen solvent ID
target_polymer_name = "polyether-imide poly(bisphenol-a-co-4- nitrophthalicanhydride-co-1,3-phenylenediamine)"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
nitrogen_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('nitrogen')]['solvent'].values[0]

# Step 3: Filter for polymer–Nitrogen data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == nitrogen_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyether-imide - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyether-imide - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find Ethanol solvent ID (replacing Methane)
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('ethanol', na=False)]

if not solv_matches.empty:
    ethanol_id = solv_matches['solvent'].values[0]
    print("Matched Ethanol solvent ID:", ethanol_id)
else:
    print("Ethanol not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("Ethanol not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–Ethanol data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == ethanol_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - Ethanol)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - Ethanol)")
plt.tight_layout()
plt.show()

"""# **3**"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find 1-Propanol solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('1-propanol', na=False)]

if not solv_matches.empty:
    propanol_id = solv_matches['solvent'].values[0]
    print("Matched 1-Propanol solvent ID:", propanol_id)
else:
    print("1-Propanol not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("1-Propanol not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–1-Propanol data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == propanol_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - 1-Propanol)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - 1-Propanol)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get Polyethylene polymer ID and Carbon Dioxide solvent ID
target_polymer_name = "polyethylene"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for polymer–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyethylene - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyethylene - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find 1-butanol solvent ID
# Using '1-butanol' but also check for 'butanol' in case data format differs
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('1-butanol|butanol', na=False)]

if not solv_matches.empty:
    butanol_id = solv_matches['solvent'].values[0]
    print("Matched 1-Butanol solvent ID:", butanol_id)
else:
    print("1-Butanol not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("1-Butanol not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–1-butanol data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == butanol_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - 1-Butanol)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - 1-Butanol)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get Polyethylene polymer ID and Nitrogen solvent ID
target_polymer_name = "polyethylene"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
nitrogen_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('nitrogen')]['solvent'].values[0]

# Step 3: Filter for polymer–Nitrogen data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == nitrogen_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyethylene - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyethylene - Nitrogen)")
plt.tight_layout()
plt.show()

"""# **4**"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find 1-pentanol solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('1-pentanol', na=False)]

if not solv_matches.empty:
    pentanol_id = solv_matches['solvent'].values[0]
    print("Matched 1-pentanol solvent ID:", pentanol_id)
else:
    print("1-pentanol not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("1-pentanol not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–1-pentanol data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == pentanol_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - 1-pentanol)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - 1-pentanol)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethylene glycol) polymer ID and Carbon Dioxide solvent ID
target_polymer_name = "poly(ethylene glycol)"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for polymer–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethylene glycol) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethylene glycol) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Find Matrimid polymer ID
poly_matches = df_pinfo[df_pinfo['abr'].str.lower().str.contains('matrimid', na=False)]

if not poly_matches.empty:
    matrimid_id = poly_matches['polymer'].values[0]
    print("Matched Matrimid polymer ID:", matrimid_id)
else:
    print("Matrimid not found. Available polymer abbreviations:")
    print(df_pinfo['abr'].dropna().unique())
    raise ValueError("Matrimid not found in polymer list. Adjust the matching pattern or data.")

# Step 3: Find 1-Hexanol solvent ID
solv_matches = df_sinfo[df_sinfo['name'].str.lower().str.contains('1-hexanol', na=False)]

if not solv_matches.empty:
    hexanol_id = solv_matches['solvent'].values[0]
    print("Matched 1-Hexanol solvent ID:", hexanol_id)
else:
    print("1-Hexanol not found. Available solvent names:")
    print(df_sinfo['name'].dropna().unique())
    raise ValueError("1-Hexanol not found in solvent list. Adjust the matching pattern or data.")

# Step 4: Filter for Matrimid–1-Hexanol data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == matrimid_id) & (df_n["solvent"] == hexanol_id)].dropna()

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Matrimid - 1-Hexanol)')
    plt.show()

for col in ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Matrimid - 1-Hexanol)")
plt.tight_layout()
plt.show()

"""104

7
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(methyl methacrylate) polymer ID and Carbon Dioxide solvent ID
target_polymer_name = "poly(methyl methacrylate)"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for polymer–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(methyl methacrylate) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(methyl methacrylate) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""6"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(lactic acid) polymer ID and Carbon Dioxide solvent ID
target_polymer_name = "poly(lactic acid)"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for polymer–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(lactic acid) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(lactic acid) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""8"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polypropylene polymer ID and Carbon Dioxide solvent ID
target_polymer_name = "polypropylene"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for polymer–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polypropylene - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polypropylene - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polypropylene polymer ID and n-butane solvent ID
target_polymer_name = "polypropylene"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
nbutane_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('n-butane')]['solvent'].values[0]

# Step 3: Filter for polymer–n-butane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == nbutane_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polypropylene - n-butane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polypropylene - n-butane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polypropylene polymer ID and 2-methylpropane solvent ID
target_polymer_name = "polypropylene"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
methylpropane_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('2-methylpropane')]['solvent'].values[0]

# Step 3: Filter for polymer–2-methylpropane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == methylpropane_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polypropylene - 2-methylpropane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polypropylene - 2-methylpropane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polypropylene polymer ID and propene solvent ID
target_polymer_name = "polypropylene"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
propene_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('propene')]['solvent'].values[0]

# Step 3: Filter for polymer–propene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == propene_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polypropylene - Propene)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polypropylene - Propene)")
plt.tight_layout()
plt.show()

"""9"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(propylene glycol) polymer ID and Carbon Dioxide solvent ID
target_polymer_name = "poly(propylene glycol)"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
co2_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('carbon dioxide')]['solvent'].values[0]

# Step 3: Filter for polymer–CO2 data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == co2_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(propylene glycol) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(propylene glycol) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""10"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polystyrene polymer ID and n-butane solvent ID
target_polymer_name = "polystyrene"
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")

target_polymer_id = polymer_row['polymer'].values[0]
nbutane_id = df_sinfo[df_sinfo['name'].str.lower().str.contains('n-butane')]['solvent'].values[0]

# Step 3: Filter for polymer–n-butane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == nbutane_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polystyrene - n-Butane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polystyrene - n-Butane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polystyrene polymer ID and 1-chloro-1,1-difluoroethane solvent ID
target_polymer_name = "polystyrene"
target_solvent_name = "1-chloro-1,1-difluoroethane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polystyrene - 1-chloro-1,1-difluoroethane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polystyrene - 1-chloro-1,1-difluoroethane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polystyrene polymer ID and 1,1,1,2-tetrafluoroethane solvent ID
target_polymer_name = "polystyrene"
target_solvent_name = "1,1,1,2-tetrafluoroethane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polystyrene - 1,1,1,2-tetrafluoroethane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polystyrene - 1,1,1,2-tetrafluoroethane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polystyrene polymer ID and 2-methylpropane solvent ID
target_polymer_name = "polystyrene"
target_solvent_name = "2-methylpropane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polystyrene - 2-methylpropane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polystyrene - 2-methylpropane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polystyrene polymer ID and nitrogen solvent ID
target_polymer_name = "polystyrene"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polystyrene - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polystyrene - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polystyrene polymer ID and carbon dioxide solvent ID
target_polymer_name = "polystyrene"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polystyrene - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polystyrene - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""12"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(vinylidene fluoride) polymer ID and carbon dioxide solvent ID
target_polymer_name = "poly(vinylidene fluoride)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(vinylidene fluoride) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(vinylidene fluoride) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""13"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(butylene succinate) polymer ID and carbon dioxide solvent ID
target_polymer_name = "poly(butylene succinate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(butylene succinate) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(butylene succinate) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""14"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(2,6-dimethyl-1,4-phenylene ether) polymer ID and carbon dioxide solvent ID
target_polymer_name = "poly(2,6-dimethyl-1,4-phenylene ether)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(2,6-dimethyl-1,4-phenylene ether) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(2,6-dimethyl-1,4-phenylene ether) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""4"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethylene glycol) polymer ID and carbon dioxide solvent ID
target_polymer_name = "poly(ethylene glycol)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethylene glycol) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethylene glycol) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethylene glycol) polymer ID and nitrogen solvent ID
target_polymer_name = "poly(ethylene glycol)"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethylene glycol) - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethylene glycol) - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethylene glycol) polymer ID and propane solvent ID
target_polymer_name = "poly(ethylene glycol)"
target_solvent_name = "propane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethylene glycol) - Propane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethylene glycol) - Propane)")
plt.tight_layout()
plt.show()

"""10-1"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polystyrene polymer ID and carbon dioxide solvent ID
target_polymer_name = "polystyrene"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–carbon dioxide data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polystyrene - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polystyrene - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""15"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(vinyl acetate) polymer ID and carbon dioxide solvent ID
target_polymer_name = "poly(vinyl acetate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–carbon dioxide data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(vinyl acetate) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(vinyl acetate) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

"""4"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethylene glycol) polymer ID and methane solvent ID
target_polymer_name = "poly(ethylene glycol)"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–methane data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethylene glycol) - Methane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethylene glycol) - Methane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethylene glycol) polymer ID and oxygen solvent ID
target_polymer_name = "poly(ethylene glycol)"
target_solvent_name = "oxygen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–oxygen data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethylene glycol) - Oxygen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethylene glycol) - Oxygen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethylene glycol) polymer ID and propene solvent ID
target_polymer_name = "poly(ethylene glycol)"
target_solvent_name = "propene"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–propene data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': filtered_df['sol-pol'].iloc[0],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethylene glycol) - Propene)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethylene glycol) - Propene)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethylene glycol) polymer ID and argon solvent ID
target_polymer_name = "poly(ethylene glycol)"
target_solvent_name = "argon"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–argon data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethylene glycol) - Argon)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethylene glycol) - Argon)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polycarbonate polymer ID and carbon dioxide solvent ID
target_polymer_name = "polycarbonate, poly(bisphenol-A carbonate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–carbon dioxide data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polycarbonate - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polycarbonate - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polyether ether ketone polymer ID and carbon dioxide solvent ID
target_polymer_name = "polyether ether ketone"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–carbon dioxide data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyether Ether Ketone - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyether Ether Ketone - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polydimethylsiloxane polymer ID and carbon dioxide solvent ID
target_polymer_name = "polydimethylsiloxane"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–carbon dioxide data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polydimethylsiloxane - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polydimethylsiloxane - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(ethyl methacrylate) polymer ID and carbon dioxide solvent ID
target_polymer_name = "poly(ethyl methacrylate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–carbon dioxide data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethyl methacrylate) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethyl methacrylate) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(trimethylsilyl)propyne polymer ID and carbon dioxide solvent ID
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–carbon dioxide data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(trimethylsilyl)propyne - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(trimethylsilyl)propyne - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(vinyltrimethyl silane)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(vinyltrimethyl silane) - Carbon Dioxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(vinyltrimethyl silane) - Carbon Dioxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(vinyltrimethyl silane)"
target_solvent_name = "dinitrogen monoxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(vinyltrimethyl silane) - Dinitrogen Monoxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(vinyltrimethyl silane) - Dinitrogen Monoxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(vinyltrimethyl silane)"
target_solvent_name = "xenon"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(vinyltrimethyl silane) - Xenon)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(vinyltrimethyl silane) - Xenon)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(trimethylsilyl)propyne - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(trimethylsilyl)propyne - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "oxygen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(trimethylsilyl)propyne - Oxygen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(trimethylsilyl)propyne - Oxygen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "argon"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(trimethylsilyl)propyne - Argon)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(trimethylsilyl)propyne - Argon)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(trimethylsilyl)propyne - Methane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(trimethylsilyl)propyne - Methane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "krypton"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(trimethylsilyl)propyne - Krypton)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(trimethylsilyl)propyne - Krypton)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "dinitrogen monoxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(trimethylsilyl)propyne - Dinitrogen Monoxide)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(trimethylsilyl)propyne - Dinitrogen Monoxide)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "xenon"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(trimethylsilyl)propyne - Xenon)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(trimethylsilyl)propyne - Xenon)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(ethyl methacrylate)"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethyl methacrylate) - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethyl methacrylate) - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(ethyl methacrylate)"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethyl methacrylate) - Methane)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethyl methacrylate) - Methane)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(ethyl methacrylate)"
target_solvent_name = "argon"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(ethyl methacrylate) - Argon)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(ethyl methacrylate) - Argon)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(methyl methacrylate)"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Poly(methyl methacrylate) - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Poly(methyl methacrylate) - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyether ether ketone"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyether ether ketone - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyether ether ketone - Nitrogen)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyether ether ketone"
target_solvent_name = "nitrogen"  # replaced argon with nitrogen here

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} (Polyether ether ketone - Nitrogen)')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title("Feature Importances (LightGBM - Polyether ether ketone - Nitrogen)")
plt.tight_layout()
plt.show()

"""2"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(e-caprolactone)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "Polyether-imide poly(bisphenol-A-co-4-nitrophthalicanhydride-co-1,3-phenylenediamine)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name.capitalize()})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name.capitalize()})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethyl silyl norbornene)"
target_solvent_name = "n-pentane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

"""18"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethyl silyl norbornene)"
target_solvent_name = "n-butane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'. Please check your data or choose different names.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get poly(trimethyl silyl norbornene) polymer ID and ethanol solvent ID
target_polymer_name = "poly(trimethyl silyl norbornene)"
target_solvent_name = "ethanol"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–ethanol data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethyl silyl norbornene)"  # updated polymer name
target_solvent_name = "1-propanol"  # updated solvent name

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)

filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethyl silyl norbornene)"
target_solvent_name = "n-butane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Define polymer and solvent names
target_polymer_name = "Polyether-imide poly(bisphenol-A-co-4- nitrophthalicanhydride-co-1,3-phenylenediamine)"
target_solvent_name = "water"

# Step 3: Get corresponding IDs
polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 4: Filter and clean data
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 5: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 6: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 7: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 8: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 9: Output results
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 10: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 11: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(propylene sebacate)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polystyrene"
target_solvent_name = "toluene"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "n-butane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "propane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "oxygen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "n-pentane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "n-heptane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "ethane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "methanol"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "1-butanol"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "acetone"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "methylacetate"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "benzene"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "hydrogen sulfide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(trimethylsilyl)propyne"
target_solvent_name = "dimethyl carbonate"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(butyl methacrylate)"
target_solvent_name = "methylethylketone"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(ethylene furanoate)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "n-butane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "propane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "propane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "oxygen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "hydrogen sulfide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "6FDA-DAM"
target_solvent_name = "1`3-butadiene"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyisobutylene"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyisobutylene"
target_solvent_name = "n-butane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyisobutylene"
target_solvent_name = "2-methylpropane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyisobutylene"
target_solvent_name = "propane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyisobutylene"
target_solvent_name = "n-pentane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyisobutylene"
target_solvent_name = "n-hexane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyisobutylene"
target_solvent_name = "isopentane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "polyisobutylene"
target_solvent_name = "neopentane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(benzyl methacrylate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly (N-vinyl-2-pyrrolidone)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly (2- hydroxyethylmethacrylate)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(2-methyl-2- adamantylmethacrylate)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(2-ethyl-2-adamantylmethacrylate)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(3,3-bis(trimethylsilyl)tricyclononene-7)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(3,3-bis(trimethylsilyl)tricyclononene-7)"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(3,3-bis(trimethylsilyl)tricyclononene-7)"
target_solvent_name = "n-butane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(3,3-bis(trimethylsilyl)tricyclononene-7)"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(3,3-bis(trimethylsilyl)tricyclononene-7)"
target_solvent_name = "propane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(3,3-bis(trimethylsilyl)tricyclononene-7)"
target_solvent_name = "oxygen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(3,3-bis(trimethylsilyl)tricyclononene-7)"
target_solvent_name = "ethane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly[1-phenyl-2-(p-tert-butylphenyl)acetylene"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly[1-phenyl-2-(p-tert-butylphenyl)acetylene"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly[1-phenyl-2-(p-tert-butylphenyl)acetylene"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly[1-phenyl-2-(p-tert-butylphenyl)acetylene"
target_solvent_name = "argon"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly[1-phenyl-2-(p-tert-butylphenyl)acetylene"
target_solvent_name = "ethane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(2,2'-(m-phenylene)-5,5'-bibenzimidazole)"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(2,2'-(m-phenylene)-5,5'-bibenzimidazole)"
target_solvent_name = "nitrogen"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(2,2'-(m-phenylene)-5,5'-bibenzimidazole)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(2,2'-(m-phenylene)-5,5'-bibenzimidazole)"
target_solvent_name = "methanol"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(vinyl chloride)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(vinyl chloride)"
target_solvent_name = "n-hexane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(vinyl chloride)"
target_solvent_name = "water"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(vinyl chloride)"
target_solvent_name = "carbon tetrachloride"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(ethyl acrylate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(decyl acrylate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(decyl acrylate)"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(behenyl acrylate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(behenyl acrylate)"
target_solvent_name = "methane"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(p-vinylbenzyltrimethyl ammonium tetrafluoroborate)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(1-vinylimidazole)"
target_solvent_name = "carbon dioxide"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(4-vinylpyridine)"
target_solvent_name ="2-propanol"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(4-vinylpyridine)"
target_solvent_name ="tert-butyl alcohol"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Suppress warnings
warnings.filterwarnings("ignore")

# Step 1: Load data
df_exp = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/experimental_dataset.csv")
df_pinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_polymers.csv")
df_sinfo = pd.read_csv("/content/drive/MyDrive/solventpolymersolubility/list_of_solvents.csv")

# Step 2: Get polymer and solvent IDs
target_polymer_name = "poly(vinyl methyl ether)"
target_solvent_name ="benzene"

polymer_row = df_pinfo[df_pinfo['name'].str.lower().str.strip() == target_polymer_name.lower().strip()]
solvent_row = df_sinfo[df_sinfo['name'].str.lower().str.strip() == target_solvent_name.lower().strip()]

if polymer_row.empty:
    raise ValueError(f"Polymer '{target_polymer_name}' not found in the list_of_polymers.csv")
if solvent_row.empty:
    raise ValueError(f"Solvent '{target_solvent_name}' not found in the list_of_solvents.csv")

target_polymer_id = polymer_row['polymer'].values[0]
target_solvent_id = solvent_row['solvent'].values[0]

# Step 3: Filter for polymer–solvent data and drop missing values
df_merge1 = pd.merge(df_pinfo, df_exp, on="polymer", how="left")
df_n = pd.merge(df_sinfo, df_merge1, on="solvent", how="left")
df_n["sol-pol"] = df_n["solvent"].astype(str) + "-" + df_n["polymer"].astype(str)
filtered_df = df_n[(df_n["polymer"] == target_polymer_id) & (df_n["solvent"] == target_solvent_id)].dropna()

if filtered_df.empty:
    raise ValueError(f"No data found for polymer '{target_polymer_name}' and solvent '{target_solvent_name}'.")

# Step 4: Prepare features and target
features = ["temperature", "pressure", "dens", "tg", "mw", "mn", "cryst"]
df_clean = filtered_df[features + ["wa", "sol-pol"]].dropna()
X = df_clean[features]
y = df_clean["wa"]

# Step 5: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 6: Train LightGBM model
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=-1,
    verbosity=-1
)
model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    callbacks=[lgb.early_stopping(50)]
)

# Step 7: Evaluate model
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# Step 8: Output sol-pol, RMSE, and R² score
output = pd.DataFrame({
    'sol-pol': [filtered_df['sol-pol'].iloc[0]],
    'RMSE': [rmse],
    'R² Score': [r2]
})
print(output)

# Step 9: Visualizations
def plot_box(x, title):
    plt.figure(figsize=(10, 6))
    sns.boxplot(data=filtered_df, x=x, y='wa')
    plt.title(f'Solubility vs {x.capitalize()} ({target_polymer_name} - {target_solvent_name})')
    plt.show()

for col in features:
    plot_box(col, f"Solubility vs {col.capitalize()}")

# Step 10: Feature Importance
importances = pd.DataFrame({
    'feature': model.feature_name_,
    'importance': model.feature_importances_
}).sort_values(by="importance", ascending=True)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=importances, palette="mako")
plt.title(f"Feature Importances (LightGBM - {target_polymer_name} - {target_solvent_name})")
plt.tight_layout()
plt.show()

